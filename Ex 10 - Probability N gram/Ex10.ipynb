{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Bigram Probability Matrix with Add-One Smoothing:\n",
      "           chinese  delicious     eat  favorite    food     for       i  \\\n",
      "chinese     0.0000     0.0000  0.0000    0.0000  0.2963  0.0000  0.0000   \n",
      "delicious   0.1053     0.0000  0.0000    0.0000  0.1053  0.0000  0.0000   \n",
      "eat         0.2308     0.0000  0.0000    0.0000  0.0769  0.0000  0.0000   \n",
      "favorite    0.0000     0.0000  0.0000    0.0000  0.0000  0.0000  0.0000   \n",
      "food        0.0000     0.0000  0.1071    0.0000  0.0000  0.1071  0.0714   \n",
      "for         0.0000     0.0000  0.0000    0.0000  0.0000  0.0000  0.0000   \n",
      "i           0.0000     0.0000  0.0000    0.0000  0.0000  0.0000  0.0000   \n",
      "is          0.0000     0.1429  0.0000    0.0000  0.0000  0.0000  0.0000   \n",
      "lunch       0.1111     0.0000  0.0741    0.0000  0.0000  0.0000  0.1111   \n",
      "meal        0.0000     0.0000  0.0000    0.0000  0.0000  0.0000  0.0000   \n",
      "money       0.0000     0.0000  0.0000    0.0000  0.0000  0.0000  0.0909   \n",
      "my          0.0000     0.0000  0.0000    0.1111  0.0000  0.0000  0.0000   \n",
      "on          0.1000     0.0000  0.0000    0.0000  0.1000  0.0000  0.0000   \n",
      "spend       0.0000     0.0000  0.0000    0.0000  0.0000  0.0000  0.0000   \n",
      "tasty       0.0000     0.0000  0.0000    0.0000  0.1111  0.0000  0.0000   \n",
      "to          0.0000     0.0000  0.2800    0.0000  0.0000  0.0000  0.0000   \n",
      "want        0.0909     0.0000  0.0000    0.0000  0.0000  0.0000  0.0000   \n",
      "\n",
      "               is   lunch    meal   money      my      on   spend   tasty  \\\n",
      "chinese    0.0000  0.1481  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "delicious  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "eat        0.0000  0.1538  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "favorite   0.0000  0.0000  0.1111  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "food       0.1071  0.0000  0.0000  0.0000  0.0000  0.0000  0.0714  0.0000   \n",
      "for        0.0000  0.1579  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "i          0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "is         0.0000  0.0000  0.0000  0.0000  0.0952  0.0000  0.0000  0.0952   \n",
      "lunch      0.1111  0.0741  0.0000  0.0000  0.0000  0.0000  0.0741  0.0000   \n",
      "meal       0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1111  0.0000   \n",
      "money      0.0000  0.0000  0.0000  0.0000  0.0000  0.1818  0.0000  0.0000   \n",
      "my         0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "on         0.0000  0.1000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "spend      0.0000  0.0000  0.0000  0.2727  0.0000  0.0000  0.0000  0.0000   \n",
      "tasty      0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "to         0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.1200  0.0000   \n",
      "want       0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000  0.0000   \n",
      "\n",
      "               to    want  \n",
      "chinese    0.0000  0.0000  \n",
      "delicious  0.0000  0.0000  \n",
      "eat        0.0000  0.0000  \n",
      "favorite   0.0000  0.0000  \n",
      "food       0.1071  0.0000  \n",
      "for        0.0000  0.0000  \n",
      "i          0.0000  0.2727  \n",
      "is         0.0000  0.0000  \n",
      "lunch      0.0741  0.0000  \n",
      "meal       0.0000  0.0000  \n",
      "money      0.0909  0.0000  \n",
      "my         0.0000  0.0000  \n",
      "on         0.0000  0.0000  \n",
      "spend      0.0000  0.0000  \n",
      "tasty      0.0000  0.0000  \n",
      "to         0.0000  0.0000  \n",
      "want       0.2273  0.0000  \n",
      "Bigram Count Matrix with Add-One Smoothing:\n",
      "           chinese  delicious  eat  favorite  food  for  i  is  lunch  meal  \\\n",
      "chinese          1          1    1         1     8    1  1   1      4     1   \n",
      "delicious        2          1    1         1     2    1  1   1      1     1   \n",
      "eat              6          1    1         1     2    1  1   1      4     1   \n",
      "favorite         1          1    1         1     1    1  1   1      1     2   \n",
      "food             1          1    3         1     1    3  2   3      1     1   \n",
      "for              1          1    1         1     1    1  1   1      3     1   \n",
      "i                1          1    1         1     1    1  1   1      1     1   \n",
      "is               1          3    1         1     1    1  1   1      1     1   \n",
      "lunch            3          1    2         1     1    1  3   3      2     1   \n",
      "meal             1          1    1         1     1    1  1   1      1     1   \n",
      "money            1          1    1         1     1    1  2   1      1     1   \n",
      "my               1          1    1         2     1    1  1   1      1     1   \n",
      "on               2          1    1         1     2    1  1   1      2     1   \n",
      "spend            1          1    1         1     1    1  1   1      1     1   \n",
      "tasty            1          1    1         1     2    1  1   1      1     1   \n",
      "to               1          1    7         1     1    1  1   1      1     1   \n",
      "want             2          1    1         1     1    1  1   1      1     1   \n",
      "\n",
      "           money  my  on  spend  tasty  to  want  \n",
      "chinese        1   1   1      1      1   1     1  \n",
      "delicious      1   1   1      1      1   1     1  \n",
      "eat            1   1   1      1      1   1     1  \n",
      "favorite       1   1   1      1      1   1     1  \n",
      "food           1   1   1      2      1   3     1  \n",
      "for            1   1   1      1      1   1     1  \n",
      "i              1   1   1      1      1   1     6  \n",
      "is             1   2   1      1      2   1     1  \n",
      "lunch          1   1   1      2      1   2     1  \n",
      "meal           1   1   1      2      1   1     1  \n",
      "money          1   1   4      1      1   2     1  \n",
      "my             1   1   1      1      1   1     1  \n",
      "on             1   1   1      1      1   1     1  \n",
      "spend          6   1   1      1      1   1     1  \n",
      "tasty          1   1   1      1      1   1     1  \n",
      "to             1   1   1      3      1   1     1  \n",
      "want           1   1   1      1      1   5     1  \n",
      "Probability of the bigram ('spend', 'money'): 0.2727272727272727\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Hema\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.util import ngrams\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "\n",
    "# Function to read text from a file\n",
    "def read_file(file_path):\n",
    "    with open(file_path, 'r') as file:\n",
    "        return file.read().lower()\n",
    "\n",
    "# Function to calculate bigram probabilities with add-one smoothing\n",
    "def add_one_smoothing(bigrams, unigram_counts, vocabulary_size):\n",
    "    bigram_counts = Counter(bigrams)\n",
    "    smoothed_probabilities = {}\n",
    "\n",
    "    for bigram in bigram_counts:\n",
    "        smoothed_probabilities[bigram] = (bigram_counts[bigram] + 1) / (unigram_counts[bigram[0]] + vocabulary_size)\n",
    "\n",
    "    return smoothed_probabilities\n",
    "\n",
    "# Generate a smoothed count matrix\n",
    "def generate_bigram_count_matrix(tokens, bigrams, vocabulary_size):\n",
    "    vocab = sorted(set(tokens))\n",
    "    unigram_counts = Counter(tokens)\n",
    "    bigram_counts = Counter(bigrams)\n",
    "\n",
    "    bigram_count_matrix = pd.DataFrame(0, index=vocab, columns=vocab, dtype=int)\n",
    "    \n",
    "    for w1 in vocab:\n",
    "        for w2 in vocab:\n",
    "            bigram_count_matrix.loc[w1, w2] = bigram_counts[(w1, w2)] + 1  # Add-One Smoothing\n",
    "\n",
    "    return bigram_count_matrix\n",
    "\n",
    "# Generate a bigram probability matrix\n",
    "def generate_bigram_probability_matrix(tokens, smoothed_probabilities):\n",
    "    vocab = sorted(set(tokens))\n",
    "    bigram_matrix = pd.DataFrame(0, index=vocab, columns=vocab, dtype=float)\n",
    "\n",
    "    for (w1, w2), prob in smoothed_probabilities.items():\n",
    "        bigram_matrix.loc[w1, w2] = prob\n",
    "\n",
    "    return bigram_matrix\n",
    "\n",
    "# Main function\n",
    "def main():\n",
    "    nltk.download('punkt')\n",
    "\n",
    "    # Read text from file\n",
    "    file_path = 'corpus.txt'  # Replace with your file path\n",
    "    text = read_file(file_path)\n",
    "\n",
    "    # Tokenize the text\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "\n",
    "    # Generate unigrams and bigrams\n",
    "    unigrams = tokens\n",
    "    bigrams = list(ngrams(tokens, 2))\n",
    "\n",
    "    # Calculate unigram counts\n",
    "    unigram_counts = Counter(unigrams)\n",
    "    vocabulary_size = len(unigram_counts)\n",
    "\n",
    "    # Apply Add-One Smoothing\n",
    "    add_one_probs = add_one_smoothing(bigrams, unigram_counts, vocabulary_size)\n",
    "\n",
    "    # Generate bigram count matrix\n",
    "    bigram_count_matrix = generate_bigram_count_matrix(tokens, bigrams, vocabulary_size)\n",
    "    \n",
    "    # Generate bigram probability matrix\n",
    "    bigram_probability_matrix = generate_bigram_probability_matrix(tokens, add_one_probs)\n",
    "\n",
    "    # Print Bigram Probability Matrix\n",
    "    print(\"\\nBigram Probability Matrix with Add-One Smoothing:\")\n",
    "    print(bigram_probability_matrix.round(4))\n",
    "\n",
    "    # Print Bigram Count Matrix\n",
    "    print(\"Bigram Count Matrix with Add-One Smoothing:\")\n",
    "    print(bigram_count_matrix)\n",
    "\n",
    "    # Prompt the user for a bigram input\n",
    "    def get_bigram_probability(smoothed_probabilities, bigram):\n",
    "        return smoothed_probabilities.get(bigram, \"Bigram not found\")\n",
    "\n",
    "    # Example usage for querying a bigram\n",
    "    random_bigram = ('spend', 'money')  # example input bigram\n",
    "    probability = get_bigram_probability(add_one_probs, random_bigram)\n",
    "    print(f\"Probability of the bigram {random_bigram}: {probability}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
